+++
date = "2026-02-02T08:45:00+01:00"
lastmod = "2026-02-02T08:45:00+01:00"
author = "Albert L.G."
title = "L’error de delegar criteri a la IA (i com evitar-lo)"
slug = "error-delegar-criteri-ia"
tags = ["ia", "criteri", "decisions", "productivitat", "pensament", "llms"]
summary = "La IA ajuda, accelera i amplifica… però no decideix per tu. Aquí explico com treballo per no delegar criteri a eines que són brillants predint paraules, però no conseqüències."
description = "Reflexió pràctica sobre com evitar delegar criteri a la IA: com funcionen els models de llenguatge, quan ajuden, quan confonen i quin sistema aplico per mantenir la responsabilitat de les decisions."
translationKey = "criterio-ia-post"
images = ["/img/post/criterio-ia.png"]
header = { image = "post/criterio-ia.png", hide_banner = true }
+++

<img class="fotobonita" style="margin: 4px;" src="/img/post/criterio-ia.png" alt="Il·lustració abstracta sobre criteri i intel·ligència artificial" width="720" />

<p>Utilitzo IA cada dia. Per treballar, per escriure, per pensar millor i, de vegades, per riure una estona. Però hi ha una línia que vigilo molt: <strong>no delegar criteri</strong>.</p>

<p>Els models de llenguatge són increïbles, sí. Però el seu punt fort no és la veritat, ni la responsabilitat, ni les conseqüències. El seu punt fort és <em>predir paraules</em>. Res més. Però tampoc menys.</p>

<p>Ho explicaré amb calma —i amb un punt d’humor— perquè m’he adonat que aquest error és cada cop més habitual: professionals deixant que la IA pensi per ells… i després preguntant-se per què les coses no acaben de quadrar.</p>

<hr/>

<h2>1. Els LLM no opinen: només prediuen</h2>

<p>Quan li demanes alguna cosa a un model de llenguatge, no està “raonant” ni “valorant” ni “decidint”.</p>

<p>Està fent una altra cosa: <strong>calculant quina paraula és més probable que vingui després</strong>.</p>

<p>És com un lloro molt llest que ha llegit tot Internet i, en lloc de repetir, improvisa constantment. Però continua sent un lloro. No té autobiografia, ni intenció, ni criteri.</p>

<p>Per això:</p>

<ul>
  <li>sona convincent… encara que s’ho inventi,</li>
  <li>respon amb seguretat… encara que no en tingui,</li>
  <li>i pot explicar-te conceptes que no entén.</li>
</ul>

<p>És brillant per accelerar, però <em>pèssim per substituir judici</em>.</p>

<hr/>

<h2>2. El risc real no és que la IA s’equivoqui: és que tu deixis de pensar</h2>

<p>Aquí és on passa tot. El risc no és tecnològic, sinó humà.</p>

<p><strong>Quan una eina et respon molt bé, molt ràpid i amb molta seguretat… és fàcil apagar el pensament crític.</strong></p>

<p>Jo mateix ho noto: quan vaig cansat, quan tinc pressa o quan només vull “sortir del pas”, la mà se’n va sola cap al teclat per preguntar a la IA.</p>

<p>I és llavors quan més alerta estic, perquè:</p>

<ul>
  <li>la velocitat convida a no revisar,</li>
  <li>la forma convida a confiar,</li>
  <li>i la comoditat convida a delegar massa.</li>
</ul>

<p>La IA no és perillosa. Perillós és utilitzar-la sense fricció.</p>

<hr/>

<h2>3. El meu sistema per no delegar criteri</h2>

<p>No és perfecte, però funciona. He acabat creant una mena de “protocol personal” perquè la IA no em faci perdre control.</p>

<h3>3.1. Regla 1: La tesi és meva. La IA només l’expandeix.</h3>

<p>No començo preguntant “què en penses?”. Començo amb <strong>el meu punt de partida</strong>.</p>

<p>La IA m’ajuda a <em>escriure millor</em>, no a <em>decidir què penso</em>.</p>

<h3>3.2. Regla 2: Si la resposta m’agrada massa ràpid, sospito</h3>

<p>És la meva alarma interna. Quan tot “encaixa” en tres segons, paro:</p>

<ul>
  <li>És correcte o només sona bé?</li>
  <li>Em reflecteix o només m’adula?</li>
  <li>Complementa o substitueix el meu criteri?</li>
</ul>

<h3>3.3. Regla 3: Sempre contrasto amb una font externa</h3>

<p>Una lectura, un company, una nota meva. El que sigui, però fora de la IA. Contrastar és el que manté viu el pensament.</p>

<h3>3.4. Regla 4: Decidir continua sent tasca humana</h3>

<p>Puc fer servir IA per entendre millor un tema, generar alternatives o accelerar processos. Però el <strong>gest de decidir</strong> —el que implica responsabilitat— continua sent meu.</p>

<hr/>

<h2>4. El futur no és IA vs humans: és IA + humans amb criteri</h2>

<p>La IA no et fa més intel·ligent. Et fa <em>més ràpid</em>. I això és un arma de doble tall.</p>

<p>Sense criteri, només accelera errors.</p>

<p>Amb criteri, és extraordinària.</p>

<p>Cap model, per molt avançat que sigui, pot:</p>

<ul>
  <li>assumir conseqüències,</li>
  <li>captar matisos humans,</li>
  <li>o prendre decisions que afecten altres persones amb responsabilitat real.</li>
</ul>

<hr/>

<h2>5. Un tancament amb humor (però seriós)</h2>

<p>Quan utilitzo IA, m’ho imagino així:</p>

<p><em>És un copilot brillant que no ha conduït mai.</em></p>

<p>Et pot comentar la carretera, proposar rutes i explicar-te cada senyal…</p>

<p>Però si li dones el volant, no tens un copilot; tens un passatger molt convençut i amb zero quilòmetres d’experiència.</p>

<p>Així que sí: faig servir IA cada dia. I m’encanta. Però el volant, de moment, el continuo portant jo.</p>

<hr/>

<p>Gràcies per llegir. Si això et serveix: endavant. Si et genera fricció: encara millor.</p>
