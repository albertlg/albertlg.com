+++
date = "2026-02-02T08:45:00+01:00"
lastmod = "2026-02-02T08:45:00+01:00"
author = "Albert L.G."
title = "El error de delegar criterio en la IA (y cómo evitarlo)"
slug = "error-delegar-criterio-ia"
tags = ["ia", "criterio", "decision", "productividad", "pensamiento", "llms"]
summary = "La IA ayuda, acelera y amplifica… pero no decide por ti. Aquí explico cómo trabajo para no delegar criterio en herramientas que son brillantes prediciendo palabras, pero no consecuencias."
description = "Reflexión práctica sobre cómo evitar delegar criterio en la IA: cómo funcionan los modelos de lenguaje, cuándo ayudan, cuándo confunden y qué sistema aplico para mantener la responsabilidad de las decisiones."
translationKey = "criterio-ia-post"
images = ["/img/post/criterio-ia.png"]
header = { image = "post/criterio-ia.png", hide_banner = true }
+++

<img class="fotobonita" style="margin: 4px;" src="/img/post/criterio-ia.png" alt="Ilustración abstracta sobre criterio e inteligencia artificial" width="720" />

<p>Utilizo IA cada día. Para trabajar, para escribir, para pensar mejor y, a veces, para reírme un rato. Pero hay una línea que vigilo mucho: <strong>no delegar criterio</strong>.</p>

<p>Porque los modelos de lenguaje son increíbles, sí. Pero su punto fuerte no es la verdad, ni la responsabilidad, ni las consecuencias. Su punto fuerte es <em>predecir palabras</em>. Nada más. Nada menos.</p>

<p>Lo explicaré con calma —y un poco de humor— porque me he dado cuenta de que este error es cada vez más común: profesionales dejando que la IA piense por ellos… y luego preguntándose por qué algo ha salido regular.</p>

<hr/>

<h2>1. Los LLM no opinan: sólo predicen</h2>

<p>Cuando le pides algo a un modelo de lenguaje, no está “razonando” ni “valorando” ni “decidiendo”.</p>

<p>Está haciendo otra cosa: <strong>calculando qué palabra es más probable que venga después</strong>.</p>

<p>Como si un loro muy listo hubiera leído todo Internet y, en lugar de repetir, improvisara sin parar. Pero sigue siendo un loro. Nada de autobiografía, nada de intención.</p>

<p>Por eso:</p>

<ul>
  <li>suena convincente… incluso cuando se inventa cosas,</li>
  <li>te da respuestas muy seguras… aunque no lo estén,</li>
  <li>y es capaz de explicarte un concepto que no entiende.</li>
</ul>

<p>Es brillante para acelerar trabajo, pero <em>pésimo para sustituir juicio</em>.</p>

<hr/>

<h2>2. El riesgo real no es que la IA se equivoque: es que tú dejes de pensar</h2>

<p>Ese es el punto crítico. El riesgo no es tecnológico, sino humano.</p>

<p><strong>Cuando algo te responde muy bien, muy rápido y con mucha seguridad… es fácil apagar tu pensamiento crítico.</strong></p>

<p>Yo lo noto en mí mismo: cuando voy cansado, cuando tengo prisa o cuando sólo quiero “salir del paso”, mi mano va sola al teclado para preguntar a la IA.</p>

<p>Y ahí es cuando más atención pongo, porque:</p>

<ul>
  <li>la velocidad invita a no revisar,</li>
  <li>la forma invita a confiar,</li>
  <li>y la comodidad invita a delegar demasiado.</li>
</ul>

<p>La IA no es peligrosa. Peligroso es usarla sin fricción.</p>

<hr/>

<h2>3. Mi sistema para evitar delegar criterio (y seguir trabajando con IA sin quemarme)</h2>

<p>No es perfecto, pero funciona. He acabado creando una especie de “protocolo personal” para no perder control cuando uso IA.</p>

<h3>3.1. Regla 1: Yo formulo la tesis. La IA sólo la desarrolla.</h3>

<p>Nunca empiezo un trabajo preguntándole “¿qué opinas de…?”. Siempre empiezo por <strong>mi punto de vista inicial</strong>.</p>

<p>La IA está para <em>ayudarme a escribir mejor</em>, no para <em>decidir qué pienso</em>.</p>

<h3>3.2. Regla 2: Si la respuesta me gusta demasiado rápido, sospecho</h3>

<p>Es mi alarma interna. Cuando algo “encaja” en 3 segundos, activo el modo crítico:</p>

<ul>
  <li>¿Suena bien o es correcto?</li>
  <li>¿Me convence o me refleja?</li>
  <li>¿Complementa o sustituye mi criterio?</li>
</ul>

<p>A veces la respuesta es tan bonita que parece “mía”, pero no siempre lo es.</p>

<h3>3.3. Regla 3: Siempre contrasto con una fuente externa</h3>

<p>Una lectura, un colega, un paper, una nota mía. Algo fuera de la IA. Porque contrastar es lo que mantiene el pensamiento vivo.</p>

<h3>3.4. Regla 4: Decidir sigue siendo tarea humana</h3>

<p>Puedo usar IA para entender mejor un tema, para generar alternativas, o para acelerar procesos. Pero el <strong>acto de decidir</strong> —lo que implica responsabilidad— sigue siendo mío.</p>

<p>No pienso subcontratar eso ni al mejor modelo del mundo.</p>

<hr/>

<h2>4. El futuro no es IA versus humanos: es IA + humanos con criterio</h2>

<p>Si algo he aprendido estos años es que la IA no te hace más inteligente. Te hace <em>más rápido</em>. Y eso es un arma de doble filo.</p>

<p>Sin criterio, sólo te hace llegar antes al mismo error.</p>

<p>Con criterio, es una herramienta extraordinaria.</p>

<p>Por eso escribo esto: porque creo que la tecnología puede hacernos mejores… pero sólo si no olvidamos lo que es insustituible.</p>

<p>La IA puede escribir textos, resumir libros, reconstruir imágenes, analizar datos. Pero todavía no he visto ningún modelo que pueda:</p>

<ul>
  <li>asumir consecuencias,</li>
  <li>entender matices humanos,</li>
  <li>o tomar decisiones que afecten a otros con verdadera responsabilidad.</li>
</ul>

<p>Y ojalá siga así un buen tiempo.</p>

<hr/>

<h2>5. Cierre (humorístico, pero serio)</h2>

<p>Cuando uso IA, suelo imaginarlo así:</p>

<p><em>Es un copiloto brillante que nunca ha conducido.</em></p>

<p>Puede comentar la carretera, puede sugerir rutas, puede explicarte qué significa cada señal…</p>

<p>Pero si le das el volante, no tienes un copiloto: tienes un pasajero muy confiado y cero kilómetros de experiencia.</p>

<p>Así que sí: uso IA cada día. Y la adoro. Pero el volante, de momento, lo sigo llevando yo.</p>

<hr/>

<p>Gracias por leer. Y como siempre: si te sirve, adelante. Si te genera fricción, mejor todavía.</p>
