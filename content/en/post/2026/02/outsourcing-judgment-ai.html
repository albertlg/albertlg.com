+++
date = "2026-02-02T08:45:00+01:00"
lastmod = "2026-02-02T08:45:00+01:00"
author = "Albert L.G."
title = "The mistake of outsourcing your judgment to AI (and how to avoid it)"
slug = "outsourcing-judgment-ai"
tags = ["ai", "judgment", "decision-making", "productivity", "thinking", "llms"]
summary = "AI helps, accelerates and amplifies… but it does not decide for you. Here’s the system I use to avoid outsourcing my judgment to tools that are brilliant at predicting words, not consequences."
description = "A practical reflection on how to avoid outsourcing judgment to AI: how language models work, when they help, when they mislead, and the system I apply to keep responsibility for the decisions I make."
translationKey = "criterio-ia-post"
images = ["/img/post/criterio-ia.png"]
header = { image = "post/criterio-ia.png", hide_banner = true }
+++

<img class="fotobonita" style="margin: 4px;" src="/img/post/criterio-ia.png" alt="Abstract illustration about judgment and artificial intelligence" width="720" />

<p>I use AI every day. For work, for writing, for thinking better and, occasionally, for laughing a bit. But there’s a line I try to keep very clear: <strong>not outsourcing my judgment</strong>.</p>

<p>Language models are incredible, yes. But their strength is not truth, responsibility or consequences. Their strength is <em>predicting words</em>. Nothing more. Nothing less.</p>

<p>I’ll explain this calmly —and with a touch of humour— because I keep seeing the same mistake over and over: people letting AI think for them… and then wondering why things feel “off”.</p>

<hr/>

<h2>1. LLMs don’t have opinions: they only predict</h2>

<p>When you ask a language model something, it is not “reasoning” or “evaluating” or “deciding”.</p>

<p>It’s doing something else entirely: <strong>calculating the most probable next word</strong>.</p>

<p>Imagine an extremely smart parrot that has read all of the Internet and improvises non-stop. But it’s still a parrot. No biography, no intention, no sense of consequence.</p>

<ul>
  <li>It sounds convincing… even when it’s wrong,</li>
  <li>it answers with confidence… even when it shouldn't,</li>
  <li>and it “explains” concepts it doesn't actually understand.</li>
</ul>

<p>It’s brilliant for acceleration, but <em>terrible for replacing judgment</em>.</p>

<hr/>

<h2>2. The real danger is not AI making mistakes: it’s you stopping thinking</h2>

<p>This is where the real risk lives. And it’s not a technological one — it’s human.</p>

<p><strong>When something answers quickly, clearly and with confidence… it’s very easy to turn off critical thinking.</strong></p>

<p>I notice it in myself: when I’m tired, in a rush or want to get something “out the door”, my instinct is to ask AI first.</p>

<p>That’s exactly when I pay the most attention because:</p>

<ul>
  <li>speed invites skipping verification,</li>
  <li>the tone invites trust,</li>
  <li>convenience invites over-delegation.</li>
</ul>

<p>AI isn’t dangerous. Using it without friction is.</p>

<hr/>

<h2>3. My system to avoid outsourcing judgment</h2>

<p>Not perfect, but effective. I’ve built a kind of “personal protocol” so AI helps me without replacing me.</p>

<h3>3.1. Rule 1: The thesis is mine. AI only develops it.</h3>

<p>I never start by asking “What do you think?”. I start with <strong>my point of view</strong>.</p>

<p>AI helps me <em>write better</em>, not <em>think for me</em>.</p>

<h3>3.2. Rule 2: If I like the answer too quickly, I get suspicious</h3>

<p>It’s my internal alarm. When everything “fits” in three seconds, I stop.</p>

<ul>
  <li>Does it sound good or is it actually correct?</li>
  <li>Does it represent me or is it just flattering?</li>
  <li>Is it complementing or replacing my judgment?</li>
</ul>

<h3>3.3. Rule 3: I always cross-check with something external</h3>

<p>A book, a colleague, a note, a real-world source. Anything outside AI. Cross-checking is what keeps thinking alive.</p>

<h3>3.4. Rule 4: Decisions are still a human task</h3>

<p>I can use AI to understand, explore alternatives or speed up execution. But the <strong>act of deciding</strong> —the one carrying responsibility— is still mine.</p>

<hr/>

<h2>4. The future isn’t AI vs humans: it’s AI + humans with judgment</h2>

<p>AI doesn’t make you smarter. It makes you <em>faster</em>. And that’s a double-edged sword.</p>

<p>Without judgment, it just accelerates mistakes.</p>

<p>With judgment, it’s extraordinary.</p>

<p>No model, no matter how advanced, can:</p>

<ul>
  <li>assume consequences,</li>
  <li>understand human nuance,</li>
  <li>or make decisions that affect others responsibly.</li>
</ul>

<hr/>

<h2>5. A closing thought (humorous, but true)</h2>

<p>When I use AI, I picture it like this:</p>

<p><em>A brilliant co-pilot who has never actually driven.</em></p>

<p>It can comment on the road, suggest routes, and explain every sign…</p>

<p>But if you hand it the wheel, you don’t have a co-pilot anymore — you have a very confident passenger with zero driving hours.</p>

<p>So yes: I use AI every day, and I love it. But for now, I’m still the one steering.</p>

<hr/>

<p>Thanks for reading. If this helps: great. If it generates friction: even better.</p>
